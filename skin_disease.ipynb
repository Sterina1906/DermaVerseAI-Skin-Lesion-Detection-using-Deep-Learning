{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1apvg2VJ_QyCAYBNxltLiGHIBo-N_S8j_",
      "authorship_tag": "ABX9TyOJ8IxWsX8Ygdp4CAoGV8vA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0717c40009c94f7aaf7154aadacc8c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89c9bbee34aa49808eb07d1f995a6cc4",
              "IPY_MODEL_b27dc5554f1c403fb1c0d160e7631d96",
              "IPY_MODEL_77e25d7d6ae2445794da038c3ecfc0ca"
            ],
            "layout": "IPY_MODEL_3da1f5a810aa41298c6c0e3c1147d71f"
          }
        },
        "89c9bbee34aa49808eb07d1f995a6cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad997f2029448bf90c9620eb5816e5b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_befe3456b8874ab08c4b912cc86fbee3",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "b27dc5554f1c403fb1c0d160e7631d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d85f8e8f2fa48ba9950f12ca897cb61",
            "max": 21355344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3df8d1162f0425283dc35df35c1f37e",
            "value": 21355344
          }
        },
        "77e25d7d6ae2445794da038c3ecfc0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a66606dad3ea4782b068c8ad7c4aaa6d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0377d1af78334268bc3ddeab1ad40eac",
            "value": "â€‡21.4M/21.4Mâ€‡[00:00&lt;00:00,â€‡47.2kB/s]"
          }
        },
        "3da1f5a810aa41298c6c0e3c1147d71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad997f2029448bf90c9620eb5816e5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "befe3456b8874ab08c4b912cc86fbee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d85f8e8f2fa48ba9950f12ca897cb61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3df8d1162f0425283dc35df35c1f37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a66606dad3ea4782b068c8ad7c4aaa6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0377d1af78334268bc3ddeab1ad40eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sterina1906/DermaVerseAI-Skin-Lesion-Detection-using-Deep-Learning/blob/main/skin_disease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyc-QQRqZVYB",
        "outputId": "d10270fa-bfc2-4710-cf7b-2b669c0c76f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan  4 09:17:04 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step1_imports.py\n",
        "\"\"\"\n",
        "Install required packages first:\n",
        "pip install torch torchvision albumentations opencv-python pandas scikit-learn timm\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import timm  # PyTorch Image Models library for EfficientNet\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "jvNwI9OMZTsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f434b371-5612-410f-891d-15bd871366dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Using device: cuda\n",
            "   GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import GroupShuffleSplit"
      ],
      "metadata": {
        "id": "gdgW9tuB58Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Your Drive paths (with spaces and parentheses)\n",
        "DRIVE_IMAGE_DIR = '/content/drive/MyDrive/skin-disease-el/ISIC2018_Task3_Training_Input (1)/ISIC2018_Task3_Training_Input/'\n",
        "DRIVE_GT_FILE = '/content/drive/MyDrive/skin-disease-el/ISIC2018_Task3_Training_GroundTruth (1)/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv'\n",
        "DRIVE_LESION_FILE = '/content/drive/MyDrive/skin-disease-el/ISIC2018_Task3_Training_LesionGroupings.csv'  # Update if you have separate lesion_grouping.csv\n",
        "\n",
        "# Create local directory\n",
        "LOCAL_DIR = '/content/local_data/'\n",
        "os.makedirs(LOCAL_DIR + 'images/', exist_ok=True)\n",
        "\n",
        "print(\"Copying images to local storage (3-5 minutes)...\")\n",
        "\n",
        "# Copy all images using Python (handles spaces properly)\n",
        "image_files = list(Path(DRIVE_IMAGE_DIR).glob('*.jpg'))\n",
        "if not image_files:\n",
        "    image_files = list(Path(DRIVE_IMAGE_DIR).glob('*.png'))\n",
        "\n",
        "print(f\"Found {len(image_files)} images\")\n",
        "\n",
        "for i, img_file in enumerate(image_files):\n",
        "    if i % 1000 == 0:\n",
        "        print(f\"Copied {i}/{len(image_files)} images...\")\n",
        "    shutil.copy2(str(img_file), LOCAL_DIR + 'images/')\n",
        "\n",
        "print(f\"âœ… All {len(image_files)} images copied!\")\n",
        "\n",
        "# Copy CSV files\n",
        "print(\"Copying CSV files...\")\n",
        "shutil.copy2(DRIVE_GT_FILE, LOCAL_DIR + 'groundtruth.csv')\n",
        "print(\"âœ… groundtruth.csv copied!\")\n",
        "\n",
        "# If you have a separate lesion_grouping.csv, update the path and uncomment:\n",
        "shutil.copy2(DRIVE_LESION_FILE, LOCAL_DIR + 'lesion_grouping.csv')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… ALL DONE! Now update your training code:\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nChange these lines in your code:\")\n",
        "print(\"DATA_DIR = '/content/local_data/'\")\n",
        "print(\"IMAGE_DIR = os.path.join(DATA_DIR, 'images')\")\n",
        "print(\"METADATA_FILE = os.path.join(DATA_DIR, 'groundtruth.csv')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1J1oofEjbpU",
        "outputId": "f80445e1-ed49-486e-eeca-23faaa8eea7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying images to local storage (3-5 minutes)...\n",
            "Found 10019 images\n",
            "Copied 0/10019 images...\n",
            "Copied 1000/10019 images...\n",
            "Copied 2000/10019 images...\n",
            "Copied 3000/10019 images...\n",
            "Copied 4000/10019 images...\n",
            "Copied 5000/10019 images...\n",
            "Copied 6000/10019 images...\n",
            "Copied 7000/10019 images...\n",
            "Copied 8000/10019 images...\n",
            "Copied 9000/10019 images...\n",
            "Copied 10000/10019 images...\n",
            "âœ… All 10019 images copied!\n",
            "Copying CSV files...\n",
            "âœ… groundtruth.csv copied!\n",
            "\n",
            "============================================================\n",
            "âœ… ALL DONE! Now update your training code:\n",
            "============================================================\n",
            "\n",
            "Change these lines in your code:\n",
            "DATA_DIR = '/content/local_data/'\n",
            "IMAGE_DIR = os.path.join(DATA_DIR, 'images')\n",
            "METADATA_FILE = os.path.join(DATA_DIR, 'groundtruth.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '/content/local_data/'  # â† Change this line only\n",
        "image_dir = os.path.join(DATA_DIR, 'images')\n",
        "disease_csv_path = os.path.join(DATA_DIR, 'groundtruth.csv')\n",
        "lesion_csv_path=os.path.join(DATA_DIR, 'lesion_grouping.csv')"
      ],
      "metadata": {
        "id": "aggldFrviil6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step2_data_preparation.py\n",
        "\"\"\"\n",
        "Prepare the dataset by:\n",
        "1. Loading CSV files\n",
        "2. Mapping diseases to binary labels (benign/malignant)\n",
        "3. Creating train/val/test splits\n",
        "4. Handling class imbalance with oversampling\n",
        "\"\"\"\n",
        "\n",
        "class DataPreparation:\n",
        "    def __init__(self, image_dir, lesion_csv_path, disease_csv_path):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_dir: Directory containing all images\n",
        "            lesion_csv_path: Path to lesion grouping CSV (image, lesion_id, diagnosis_confirm_type)\n",
        "            disease_csv_path: Path to disease CSV (image, disease_label)\n",
        "        \"\"\"\n",
        "        self.image_dir = image_dir\n",
        "        self.lesion_df = pd.read_csv(lesion_csv_path)\n",
        "        self.disease_df = pd.read_csv(disease_csv_path)\n",
        "\n",
        "        # Malignant diseases\n",
        "        self.malignant_diseases = ['AKIEC', 'MEL', 'BCC']\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"ðŸ“Š DATA PREPARATION\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Lesion CSV shape: {self.lesion_df.shape}\")\n",
        "        print(f\"Disease CSV shape: {self.disease_df.shape}\")\n",
        "\n",
        "    def create_binary_labels(self):\n",
        "      \"\"\"\n",
        "      Create binary labels: 0 = Benign, 1 = Malignant\n",
        "      \"\"\"\n",
        "      # Malignant disease columns\n",
        "      malignant_cols = ['AKIEC', 'MEL', 'BCC']\n",
        "\n",
        "      # Binary label: 1 if image belongs to any malignant class\n",
        "      self.disease_df['label'] = self.disease_df[malignant_cols].max(axis=1)\n",
        "\n",
        "      # Add full image path\n",
        "      self.disease_df['image_path'] = self.disease_df['image'].apply(\n",
        "          lambda x: os.path.join(self.image_dir, x + '.jpg')\n",
        "      )\n",
        "\n",
        "      # Filter only existing images\n",
        "      self.disease_df = self.disease_df[\n",
        "          self.disease_df['image_path'].apply(os.path.exists)\n",
        "      ].reset_index(drop=True)\n",
        "\n",
        "      print(f\"\\nâœ… Binary labels created:\")\n",
        "      print(f\"   Total images: {len(self.disease_df)}\")\n",
        "      print(f\"   Benign (0): {(self.disease_df['label'] == 0).sum()}\")\n",
        "      print(f\"   Malignant (1): {(self.disease_df['label'] == 1).sum()}\")\n",
        "      print(f\"   Class ratio (Benign:Malignant): \"\n",
        "            f\"{(self.disease_df['label'] == 0).sum()}:\"\n",
        "            f\"{(self.disease_df['label'] == 1).sum()}\")\n",
        "\n",
        "      return self.disease_df\n",
        "\n",
        "\n",
        "    def create_stratified_splits(self, test_size=0.15, val_size=0.15, random_state=42):\n",
        "        \"\"\"\n",
        "        Create train/val/test splits with stratification\n",
        "        \"\"\"\n",
        "        df = self.create_binary_labels()\n",
        "\n",
        "        # First split: separate test set\n",
        "        train_val_df, test_df = train_test_split(\n",
        "            df,\n",
        "            test_size=test_size,\n",
        "            stratify=df['label'],\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        # Second split: separate validation set from training\n",
        "        val_size_adjusted = val_size / (1 - test_size)  # Adjust val_size proportion\n",
        "        train_df, val_df = train_test_split(\n",
        "            train_val_df,\n",
        "            test_size=val_size_adjusted,\n",
        "            stratify=train_val_df['label'],\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        print(f\"\\nâœ… Dataset splits created:\")\n",
        "        print(f\"   Training: {len(train_df)} images\")\n",
        "        print(f\"      - Benign: {(train_df['label'] == 0).sum()}\")\n",
        "        print(f\"      - Malignant: {(train_df['label'] == 1).sum()}\")\n",
        "        print(f\"   Validation: {len(val_df)} images\")\n",
        "        print(f\"      - Benign: {(val_df['label'] == 0).sum()}\")\n",
        "        print(f\"      - Malignant: {(val_df['label'] == 1).sum()}\")\n",
        "        print(f\"   Test: {len(test_df)} images\")\n",
        "        print(f\"      - Benign: {(test_df['label'] == 0).sum()}\")\n",
        "        print(f\"      - Malignant: {(test_df['label'] == 1).sum()}\")\n",
        "\n",
        "        return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Usage example:\n",
        "data_prep = DataPreparation(\n",
        "    image_dir = image_dir,\n",
        "    disease_csv_path = disease_csv_path,\n",
        "    lesion_csv_path=lesion_csv_path\n",
        ")\n",
        "\n",
        "# Create splits\n",
        "train_df, val_df, test_df = data_prep.create_stratified_splits()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oj4WTF-z_rj",
        "outputId": "8ecc180c-a4b2-4a32-be48-4bac146214e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ðŸ“Š DATA PREPARATION\n",
            "============================================================\n",
            "Lesion CSV shape: (10015, 3)\n",
            "Disease CSV shape: (10015, 8)\n",
            "\n",
            "âœ… Binary labels created:\n",
            "   Total images: 10015\n",
            "   Benign (0): 8061\n",
            "   Malignant (1): 1954\n",
            "   Class ratio (Benign:Malignant): 8061:1954\n",
            "\n",
            "âœ… Dataset splits created:\n",
            "   Training: 7009 images\n",
            "      - Benign: 5641\n",
            "      - Malignant: 1368\n",
            "   Validation: 1503 images\n",
            "      - Benign: 1210\n",
            "      - Malignant: 293\n",
            "   Test: 1503 images\n",
            "      - Benign: 1210\n",
            "      - Malignant: 293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step3_augmentation.py\n",
        "\"\"\"\n",
        "Data augmentation pipelines using Albumentations\n",
        "\"\"\"\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def get_train_transforms(img_size=224):\n",
        "    \"\"\"\n",
        "    Training augmentations - aggressive to handle class imbalance\n",
        "    Applied to training data only\n",
        "    \"\"\"\n",
        "    return A.Compose([\n",
        "        # Resize to standard input size\n",
        "        A.Resize(img_size, img_size),\n",
        "\n",
        "        # Geometric transformations\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.3),\n",
        "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
        "\n",
        "        # Add noise and blur (simulate real-world variations)\n",
        "        A.OneOf([\n",
        "            A.GaussNoise(p=1.0),\n",
        "            A.GaussianBlur(p=1.0),\n",
        "            A.MotionBlur(p=1.0),\n",
        "        ], p=0.3),\n",
        "\n",
        "        # Distortions\n",
        "        A.OneOf([\n",
        "            A.OpticalDistortion(distort_limit=0.5),\n",
        "            A.GridDistortion(num_steps=5, distort_limit=0.3),\n",
        "        ], p=0.3),\n",
        "\n",
        "        # Color adjustments (handle different lighting, skin tones)\n",
        "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
        "\n",
        "        # Normalize using ImageNet statistics (required for pre-trained models)\n",
        "        A.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        ),\n",
        "\n",
        "        # Convert to PyTorch tensor\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "\n",
        "def get_val_transforms(img_size=224):\n",
        "    \"\"\"\n",
        "    Validation/Test preprocessing - no augmentation, only resize and normalize\n",
        "    Applied to validation and test data\n",
        "    \"\"\"\n",
        "    return A.Compose([\n",
        "        # Resize to standard input size\n",
        "        A.Resize(img_size, img_size),\n",
        "\n",
        "        # Normalize using ImageNet statistics\n",
        "        A.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        ),\n",
        "\n",
        "        # Convert to PyTorch tensor\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "\n",
        "print(\"âœ… Augmentation pipelines defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxBgQeE6-ybL",
        "outputId": "2a56923f-b172-4ce3-e543-08e589c50f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Augmentation pipelines defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step4_dataset.py\n",
        "\"\"\"\n",
        "Custom PyTorch Dataset for binary skin lesion classification\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "class SkinLesionBinaryDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset for binary skin lesion classification (Benign vs Malignant)\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe: Pandas DataFrame with columns ['image_path', 'label']\n",
        "            transform: Albumentations transform pipeline\n",
        "        \"\"\"\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "        # Binary classification\n",
        "        self.class_to_idx = {'Benign': 0, 'Malignant': 1}\n",
        "        self.idx_to_class = {0: 'Benign', 1: 'Malignant'}\n",
        "\n",
        "        print(f\"âœ… Dataset initialized with {len(self.df)} images\")\n",
        "        print(f\"   Class distribution: {dict(self.df['label'].value_counts())}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Load and preprocess a single image\n",
        "\n",
        "        Returns:\n",
        "            image: Preprocessed tensor [3, 224, 224]\n",
        "            label: Binary class (0=Benign, 1=Malignant)\n",
        "        \"\"\"\n",
        "        img_path = self.df.iloc[idx]['image_path']\n",
        "        label = self.df.iloc[idx]['label']\n",
        "\n",
        "        # Load image using OpenCV\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
        "\n",
        "        # Convert BGR to RGB (OpenCV loads as BGR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Apply transformations (resize, augment, normalize, convert to tensor)\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def get_class_distribution(self):\n",
        "        \"\"\"Return class distribution for weighted sampling\"\"\"\n",
        "        return self.df['label'].value_counts().to_dict()\n",
        "\n",
        "\n",
        "print(\"âœ… Custom Dataset class defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PVe07XZ-9zp",
        "outputId": "40848d94-ae6a-4f0a-c792-e2b91a5e968b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Custom Dataset class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step5_sampler.py\n",
        "\"\"\"\n",
        "Create weighted sampler to handle class imbalance during training\n",
        "This oversamples the minority class (malignant) during training\n",
        "\"\"\"\n",
        "\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "import numpy as np\n",
        "\n",
        "def create_weighted_sampler(dataset):\n",
        "    \"\"\"\n",
        "    Create WeightedRandomSampler to handle class imbalance\n",
        "\n",
        "    Args:\n",
        "        dataset: PyTorch Dataset object\n",
        "\n",
        "    Returns:\n",
        "        WeightedRandomSampler for DataLoader\n",
        "    \"\"\"\n",
        "    # Get all labels\n",
        "    labels = dataset.df['label'].values.astype(np.int64)\n",
        "\n",
        "    # Count samples per class\n",
        "    class_counts = np.bincount(labels)\n",
        "\n",
        "    # Calculate weights for each class (inverse of frequency)\n",
        "    class_weights = 1.0 / class_counts\n",
        "\n",
        "    # Assign weight to each sample based on its class\n",
        "    sample_weights = class_weights[labels]\n",
        "\n",
        "    # Create sampler\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=sample_weights,\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True\n",
        "    )\n",
        "\n",
        "    print(f\"âœ… Weighted sampler created:\")\n",
        "    print(f\"   Class counts: Benign={class_counts[0]}, Malignant={class_counts[1]}\")\n",
        "    print(f\"   Class weights: Benign={class_weights[0]:.4f}, Malignant={class_weights[1]:.4f}\")\n",
        "    print(f\"   This will oversample malignant cases during training!\")\n",
        "\n",
        "    return sampler\n",
        "\n",
        "\n",
        "print(\"âœ… Weighted sampler function defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrzyhJOx_Cdl",
        "outputId": "e5ce6dfb-f12b-4442-9a09-807db4d9a05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Weighted sampler function defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step6_dataloaders.py\n",
        "\"\"\"\n",
        "Create DataLoaders with weighted sampling for training\n",
        "\"\"\"\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_dataloaders(train_df, val_df, test_df, batch_size=32, num_workers=2, img_size=224):\n",
        "    \"\"\"\n",
        "    Create train, validation, and test DataLoaders\n",
        "\n",
        "    Args:\n",
        "        train_df, val_df, test_df: DataFrames with image paths and labels\n",
        "        batch_size: Batch size for training\n",
        "        num_workers: Number of workers for data loading\n",
        "        img_size: Input image size\n",
        "\n",
        "    Returns:\n",
        "        train_loader, val_loader, test_loader\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸ”„ CREATING DATALOADERS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = SkinLesionBinaryDataset(\n",
        "        train_df,\n",
        "        transform=get_train_transforms(img_size=img_size)\n",
        "    )\n",
        "\n",
        "    val_dataset = SkinLesionBinaryDataset(\n",
        "        val_df,\n",
        "        transform=get_val_transforms(img_size=img_size)\n",
        "    )\n",
        "\n",
        "    test_dataset = SkinLesionBinaryDataset(\n",
        "        test_df,\n",
        "        transform=get_val_transforms(img_size=img_size)\n",
        "    )\n",
        "\n",
        "    # Create weighted sampler for training (to handle imbalance)\n",
        "    train_sampler = create_weighted_sampler(train_dataset)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        sampler=train_sampler,  # Use weighted sampler instead of shuffle\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"\\nâœ… DataLoaders created:\")\n",
        "    print(f\"   Training batches: {len(train_loader)}\")\n",
        "    print(f\"   Validation batches: {len(val_loader)}\")\n",
        "    print(f\"   Test batches: {len(test_loader)}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "IMG_SIZE = 224\n",
        "\n",
        "print(\"âœ… DataLoader creation function defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AZV6d4O_Pi0",
        "outputId": "09fd70c4-9b31-4853-e61d-380eab455047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… DataLoader creation function defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step7_model.py\n",
        "\"\"\"\n",
        "Define EfficientNet-B0 model for binary classification\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class EfficientNetB0Binary(nn.Module):\n",
        "    \"\"\"\n",
        "    EfficientNet-B0 for binary classification (Benign vs Malignant)\n",
        "    Uses pretrained weights from ImageNet\n",
        "    \"\"\"\n",
        "    def __init__(self, pretrained=True, num_classes=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pretrained: Use ImageNet pretrained weights\n",
        "            num_classes: 1 for binary classification with BCEWithLogitsLoss\n",
        "        \"\"\"\n",
        "        super(EfficientNetB0Binary, self).__init__()\n",
        "\n",
        "        # Load pretrained EfficientNet-B0\n",
        "        self.backbone = timm.create_model(\n",
        "            'efficientnet_b0',\n",
        "            pretrained=pretrained,\n",
        "            num_classes=0,  # Remove classification head\n",
        "            global_pool=''  # Remove global pooling\n",
        "        )\n",
        "\n",
        "        # Get number of features from backbone\n",
        "        self.num_features = self.backbone.num_features\n",
        "\n",
        "        # Global average pooling\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(self.num_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor [batch_size, 3, 224, 224]\n",
        "\n",
        "        Returns:\n",
        "            logits: Output tensor [batch_size, 1] for binary classification\n",
        "        \"\"\"\n",
        "        # Extract features\n",
        "        features = self.backbone(x)  # [batch_size, num_features, 7, 7]\n",
        "\n",
        "        # Global pooling\n",
        "        pooled = self.global_pool(features)  # [batch_size, num_features, 1, 1]\n",
        "        pooled = pooled.flatten(1)  # [batch_size, num_features]\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(pooled)  # [batch_size, 1]\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "def create_model(pretrained=True, device='cuda'):\n",
        "    \"\"\"\n",
        "    Create and initialize the model\n",
        "    \"\"\"\n",
        "    model = EfficientNetB0Binary(pretrained=pretrained, num_classes=1)\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸ¤– MODEL ARCHITECTURE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Model: EfficientNet-B0\")\n",
        "    print(f\"Pretrained: {pretrained}\")\n",
        "    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "print(\"âœ… Model architecture defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exj6fRF-_Tor",
        "outputId": "8f987925-d6d9-4d0f-9c66-e0ed99ba4f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model architecture defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step8_training.py\n",
        "\"\"\"\n",
        "Training and evaluation functions\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    \"\"\"\n",
        "    Train for one epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch} [Train]')\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.float().unsqueeze(1).to(device)  # [batch_size, 1]\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Get predictions\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs >= 0.5).float()\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    # Calculate metrics\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def validate(model, val_loader, criterion, device, epoch):\n",
        "    \"\"\"\n",
        "    Validate the model\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    pbar = tqdm(val_loader, desc=f'Epoch {epoch} [Val]')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in pbar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # Get predictions\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs >= 0.5).float()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    # Calculate metrics\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    epoch_precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "    epoch_recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "    epoch_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "    try:\n",
        "        epoch_auc = roc_auc_score(all_labels, all_probs)\n",
        "    except:\n",
        "        epoch_auc = 0.0\n",
        "\n",
        "    return epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1, epoch_auc\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
        "                num_epochs, device, save_path='best_model.pth'):\n",
        "    \"\"\"\n",
        "    Complete training loop\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸš€ STARTING TRAINING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    best_val_auc = 0.0\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': [], 'val_precision': [],\n",
        "        'val_recall': [], 'val_f1': [], 'val_auc': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, device, epoch\n",
        "        )\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1, val_auc = validate(\n",
        "            model, val_loader, criterion, device, epoch\n",
        "        )\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step(val_auc)\n",
        "\n",
        "        # Save metrics\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_precision'].append(val_precision)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['val_f1'].append(val_f1)\n",
        "        history['val_auc'].append(val_auc)\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"\\nðŸ“Š Epoch {epoch} Results:\")\n",
        "        print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"   Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "        print(f\"   Val Precision: {val_precision:.4f} | Val Recall: {val_recall:.4f}\")\n",
        "        print(f\"   Val F1: {val_f1:.4f} | Val AUC: {val_auc:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_auc': val_auc,\n",
        "            }, save_path)\n",
        "            print(f\"   âœ… Best model saved! (AUC: {val_auc:.4f})\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"âœ… TRAINING COMPLETE!\")\n",
        "    print(f\"   Best Validation AUC: {best_val_auc:.4f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "print(\"âœ… Training functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a40ETb6I_XHe",
        "outputId": "a27917e1-f5f7-4cec-af0e-ed78d0e1c89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Training functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step9_evaluation.py\n",
        "\"\"\"\n",
        "Model evaluation and testing functions\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                            roc_auc_score, roc_curve, accuracy_score)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate model on test set\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸ“Š EVALUATING MODEL ON TEST SET\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc='Testing'):\n",
        "            images = images.to(device)\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(images)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs >= 0.5).float()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_preds = np.array(all_preds).flatten()\n",
        "    all_probs = np.array(all_probs).flatten()\n",
        "    all_labels = np.array(all_labels).flatten()\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_acc = accuracy_score(all_labels, all_preds)\n",
        "    test_auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    print(f\"\\nâœ… Test Results:\")\n",
        "    print(f\"   Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"   AUC-ROC: {test_auc:.4f}\")\n",
        "\n",
        "    # Classification report\n",
        "    print(f\"\\nðŸ“‹ Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds,\n",
        "                                target_names=['Benign', 'Malignant'],\n",
        "                                digits=4))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    print(f\"\\nðŸ”¢ Confusion Matrix:\")\n",
        "    print(f\"              Predicted\")\n",
        "    print(f\"              Benign  Malignant\")\n",
        "    print(f\"Actual Benign    {cm[0][0]:5d}  {cm[0][1]:5d}\")\n",
        "    print(f\"       Malignant {cm[1][0]:5d}  {cm[1][1]:5d}\")\n",
        "\n",
        "    return all_labels, all_preds, all_probs, cm\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, save_path='confusion_matrix.png'):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Benign', 'Malignant'],\n",
        "                yticklabels=['Benign', 'Malignant'])\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"âœ… Confusion matrix saved to {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_roc_curve(labels, probs, save_path='roc_curve.png'):\n",
        "    \"\"\"\n",
        "    Plot ROC curve\n",
        "    \"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(labels, probs)\n",
        "    auc = roc_auc_score(labels, probs)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.4f})', linewidth=2)\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve - Binary Classification')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"âœ… ROC curve saved to {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_training_history(history, save_path='training_history.png'):\n",
        "    \"\"\"\n",
        "    Plot training history\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Loss\n",
        "    axes[0, 0].plot(history['train_loss'], label='Train Loss')\n",
        "    axes[0, 0].plot(history['val_loss'], label='Val Loss')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].set_title('Training and Validation Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(alpha=0.3)\n",
        "    # Accuracy\n",
        "    axes[0, 1].plot(history['train_acc'], label='Train Acc')\n",
        "    axes[0, 1].plot(history['val_acc'], label='Val Acc')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Accuracy')\n",
        "    axes[0, 1].set_title('Training and Validation Accuracy')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "    # F1 Score\n",
        "    axes[1, 0].plot(history['val_f1'], label='Val F1', color='green')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('F1 Score')\n",
        "    axes[1, 0].set_title('Validation F1 Score')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "    # AUC\n",
        "    axes[1, 1].plot(history['val_auc'], label='Val AUC', color='red')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('AUC')\n",
        "    axes[1, 1].set_title('Validation AUC-ROC')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"âœ… Training history saved to {save_path}\")\n",
        "    plt.show()\n",
        "    print(\"âœ… Evaluation functions defined!\")"
      ],
      "metadata": {
        "id": "eMh55BbmNSeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step10_main_training.py\n",
        "\"\"\"\n",
        "Main training script - Puts everything together\n",
        "Run this file after defining all previous steps (Step 1-9)\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Import all previous step functions\n",
        "# Make sure all Step1-9 files are in the same directory or imported properly\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration class for all hyperparameters and paths\"\"\"\n",
        "\n",
        "    # ==================== PATHS (ðŸ”´ UPDATE THESE) ====================\n",
        "    IMAGE_DIR = image_dir  # Directory containing all .jpg images\n",
        "    LESION_CSV = lesion_csv_path  # CSV with image, lesion_id, diagnosis_confirm_type\n",
        "    DISEASE_CSV = disease_csv_path  # CSV with image and disease columns\n",
        "\n",
        "    # ==================== MODEL SETTINGS ====================\n",
        "    PRETRAINED = True  # Use ImageNet pretrained weights\n",
        "    MODEL_SAVE_PATH = 'best_efficientnet_b0_binary.pth'\n",
        "\n",
        "    # ==================== TRAINING HYPERPARAMETERS ====================\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_EPOCHS = 30\n",
        "    LEARNING_RATE = 1e-4  # Initial learning rate\n",
        "    WEIGHT_DECAY = 1e-5  # L2 regularization\n",
        "\n",
        "    # ==================== DATA SETTINGS ====================\n",
        "    IMG_SIZE = 224  # EfficientNet-B0 input size\n",
        "    NUM_WORKERS = 2  # DataLoader workers (increase if you have more CPU cores)\n",
        "    TEST_SIZE = 0.15  # 15% for testing\n",
        "    VAL_SIZE = 0.15  # 15% for validation\n",
        "\n",
        "    # ==================== DEVICE ====================\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # ==================== REPRODUCIBILITY ====================\n",
        "    SEED = 42\n",
        "\n",
        "    # ==================== OUTPUT SETTINGS ====================\n",
        "    SAVE_PLOTS = True\n",
        "    PLOT_DIR = 'plots'  # Directory to save plots\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# HELPER FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def print_section(title):\n",
        "    \"\"\"Print formatted section header\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"  {title}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "\n",
        "def create_output_directories(config):\n",
        "    \"\"\"Create directories for saving outputs\"\"\"\n",
        "    if config.SAVE_PLOTS:\n",
        "        os.makedirs(config.PLOT_DIR, exist_ok=True)\n",
        "        print(f\"âœ… Output directory created: {config.PLOT_DIR}\")\n",
        "\n",
        "\n",
        "def verify_paths(config):\n",
        "    \"\"\"Verify that all required paths exist\"\"\"\n",
        "    print_section(\"ðŸ” VERIFYING PATHS\")\n",
        "\n",
        "    paths_to_check = {\n",
        "        'Image Directory': config.IMAGE_DIR,\n",
        "        'Lesion CSV': config.LESION_CSV,\n",
        "        'Disease CSV': config.DISEASE_CSV\n",
        "    }\n",
        "\n",
        "    all_exist = True\n",
        "    for name, path in paths_to_check.items():\n",
        "        exists = os.path.exists(path)\n",
        "        status = \"âœ…\" if exists else \"âŒ\"\n",
        "        print(f\"{status} {name}: {path}\")\n",
        "        if not exists:\n",
        "            all_exist = False\n",
        "\n",
        "    if not all_exist:\n",
        "        print(\"\\nâŒ ERROR: Some required paths do not exist!\")\n",
        "        print(\"Please update the paths in Config class and try again.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(\"\\nâœ… All paths verified!\")\n",
        "\n",
        "\n",
        "def print_device_info(device):\n",
        "    \"\"\"Print device information\"\"\"\n",
        "    print_section(\"ðŸ’» DEVICE INFORMATION\")\n",
        "    print(f\"Device: {device}\")\n",
        "    if device.type == 'cuda':\n",
        "        print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    else:\n",
        "        print(\"âš ï¸  Warning: Running on CPU. Training will be slower.\")\n",
        "        print(\"   Consider using a GPU for faster training.\")\n",
        "\n",
        "\n",
        "def print_dataset_info(train_df, val_df, test_df):\n",
        "    \"\"\"Print dataset statistics\"\"\"\n",
        "    print_section(\"ðŸ“Š DATASET STATISTICS\")\n",
        "\n",
        "    total = len(train_df) + len(val_df) + len(test_df)\n",
        "\n",
        "    print(f\"\\nTotal Images: {total}\")\n",
        "    print(f\"\\n{'Split':<12} {'Total':<8} {'Benign':<8} {'Malignant':<10} {'Ratio (B:M)'}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for name, df in [('Training', train_df), ('Validation', val_df), ('Test', test_df)]:\n",
        "        total_imgs = len(df)\n",
        "        benign = (df['label'] == 0).sum()\n",
        "        malignant = (df['label'] == 1).sum()\n",
        "        ratio = f\"{benign}:{malignant}\"\n",
        "        print(f\"{name:<12} {total_imgs:<8} {benign:<8} {malignant:<10} {ratio}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Class Imbalance Information:\")\n",
        "    train_benign = (train_df['label'] == 0).sum()\n",
        "    train_malignant = (train_df['label'] == 1).sum()\n",
        "    imbalance_ratio = train_benign / train_malignant\n",
        "    print(f\"Training set imbalance ratio: {imbalance_ratio:.2f}:1 (Benign:Malignant)\")\n",
        "    print(f\"This means benign samples are {imbalance_ratio:.1f}x more common\")\n",
        "    print(\"âœ… Weighted sampling will be used to handle this imbalance!\")\n",
        "\n",
        "\n",
        "def calculate_pos_weight(train_df):\n",
        "    \"\"\"Calculate positive class weight for BCEWithLogitsLoss\"\"\"\n",
        "    benign_count = (train_df['label'] == 0).sum()\n",
        "    malignant_count = (train_df['label'] == 1).sum()\n",
        "    pos_weight = benign_count / malignant_count\n",
        "    return pos_weight\n",
        "\n",
        "\n",
        "def print_training_setup(criterion, optimizer, scheduler, pos_weight):\n",
        "    \"\"\"Print training setup information\"\"\"\n",
        "    print_section(\"âš™ï¸  TRAINING SETUP\")\n",
        "\n",
        "    print(f\"\\nðŸ“‰ Loss Function: BCEWithLogitsLoss\")\n",
        "    print(f\"   - Positive Weight: {pos_weight:.2f}\")\n",
        "    print(f\"   - This gives {pos_weight:.1f}x more importance to malignant samples\")\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ Optimizer: AdamW\")\n",
        "    print(f\"   - Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
        "    print(f\"   - Weight Decay: {optimizer.param_groups[0]['weight_decay']}\")\n",
        "\n",
        "    print(f\"\\nðŸ“… Scheduler: ReduceLROnPlateau\")\n",
        "    print(f\"   - Mode: Maximize (monitoring validation AUC)\")\n",
        "    print(f\"   - Factor: 0.5 (halves learning rate)\")\n",
        "    print(f\"   - Patience: 3 epochs\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "\n",
        "    # Print header\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"  ðŸ¥ BINARY SKIN LESION CLASSIFICATION PIPELINE\")\n",
        "    print(\"  ðŸ“Š Benign vs Malignant Classification using EfficientNet-B0\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Initialize config\n",
        "    config = Config()\n",
        "\n",
        "    # Verify paths exist\n",
        "    verify_paths(config)\n",
        "\n",
        "    # Create output directories\n",
        "    create_output_directories(config)\n",
        "\n",
        "    # Print device info\n",
        "    print_device_info(config.DEVICE)\n",
        "\n",
        "    # Set random seed for reproducibility\n",
        "    print_section(\"ðŸŽ² SETTING RANDOM SEED\")\n",
        "    set_seed(config.SEED)\n",
        "    print(f\"âœ… Random seed set to {config.SEED} for reproducibility\")\n",
        "\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 1: DATA PREPARATION\n",
        "    # ========================================================================\n",
        "    print_section(\"ðŸ“‚ STEP 1: DATA PREPARATION\")\n",
        "\n",
        "    print(\"\\nInitializing DataPreparation class...\")\n",
        "    data_prep = DataPreparation(\n",
        "        image_dir=config.IMAGE_DIR,\n",
        "        lesion_csv_path=config.LESION_CSV,\n",
        "        disease_csv_path=config.DISEASE_CSV\n",
        "    )\n",
        "\n",
        "    print(\"\\nCreating stratified train/val/test splits...\")\n",
        "    train_df, val_df, test_df = data_prep.create_stratified_splits(\n",
        "        test_size=config.TEST_SIZE,\n",
        "        val_size=config.VAL_SIZE,\n",
        "        random_state=config.SEED\n",
        "    )\n",
        "\n",
        "    print_dataset_info(train_df, val_df, test_df)\n",
        "\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 2: CREATE DATALOADERS\n",
        "    # ========================================================================\n",
        "    print_section(\"ðŸ”„ STEP 2: CREATING DATALOADERS\")\n",
        "\n",
        "    print(\"\\nInitializing datasets with augmentation pipelines...\")\n",
        "    train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset = create_dataloaders(\n",
        "        train_df=train_df,\n",
        "        val_df=val_df,\n",
        "        test_df=test_df,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        num_workers=config.NUM_WORKERS,\n",
        "        img_size=config.IMG_SIZE\n",
        "    )\n",
        "\n",
        "    print(f\"\\nâœ… DataLoaders Summary:\")\n",
        "    print(f\"   Batch Size: {config.BATCH_SIZE}\")\n",
        "    print(f\"   Training Batches: {len(train_loader)} ({len(train_dataset)} images)\")\n",
        "    print(f\"   Validation Batches: {len(val_loader)} ({len(val_dataset)} images)\")\n",
        "    print(f\"   Test Batches: {len(test_loader)} ({len(test_dataset)} images)\")\n",
        "    print(f\"   Note: Training uses weighted sampling to oversample malignant cases\")\n",
        "\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 3: CREATE MODEL\n",
        "    # ========================================================================\n",
        "    print_section(\"ðŸ¤– STEP 3: CREATING MODEL\")\n",
        "\n",
        "    print(\"\\nInitializing EfficientNet-B0...\")\n",
        "    model = create_model(pretrained=config.PRETRAINED, device=config.DEVICE)\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"\\nâœ… Model Summary:\")\n",
        "    print(f\"   Architecture: EfficientNet-B0\")\n",
        "    print(f\"   Pretrained: {config.PRETRAINED}\")\n",
        "    print(f\"   Total Parameters: {total_params:,}\")\n",
        "    print(f\"   Trainable Parameters: {trainable_params:,}\")\n",
        "    print(f\"   Model Size: ~{total_params * 4 / 1e6:.1f} MB\")\n",
        "    print(f\"   Device: {config.DEVICE}\")\n",
        "\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 4: DEFINE LOSS, OPTIMIZER, SCHEDULER\n",
        "    # ========================================================================\n",
        "    print_section(\"âš™ï¸  STEP 4: SETTING UP TRAINING COMPONENTS\")\n",
        "\n",
        "    # Calculate positive weight for loss function\n",
        "    pos_weight_value = calculate_pos_weight(train_df)\n",
        "    pos_weight = torch.tensor([pos_weight_value]).to(config.DEVICE)\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config.LEARNING_RATE,\n",
        "        weight_decay=config.WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='max',  # Maximize validation AUC\n",
        "        factor=0.5,  # Reduce LR by half\n",
        "        patience=3,\n",
        "        min_lr=1e-7\n",
        "    )\n",
        "\n",
        "    print_training_setup(criterion, optimizer, scheduler, pos_weight_value)\n",
        "\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 5: TRAIN MODEL\n",
        "    # ========================================================================\n",
        "    print_section(\"ðŸ‹ï¸  STEP 5: TRAINING MODEL\")\n",
        "\n",
        "    print(f\"\\nStarting training for {config.NUM_EPOCHS} epochs...\")\n",
        "    print(f\"Model will be saved to: {config.MODEL_SAVE_PATH}\")\n",
        "    print(f\"\\nTraining Configuration:\")\n",
        "    print(f\"   Epochs: {config.NUM_EPOCHS}\")\n",
        "    print(f\"   Batch Size: {config.BATCH_SIZE}\")\n",
        "    print(f\"   Learning Rate: {config.LEARNING_RATE}\")\n",
        "    print(f\"   Weight Decay: {config.WEIGHT_DECAY}\")\n",
        "    print(f\"\\nMetrics tracked: Loss, Accuracy, Precision, Recall, F1, AUC-ROC\")\n",
        "    print(f\"Best model selection: Based on highest validation AUC-ROC\")\n",
        "\n",
        "    history = train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        num_epochs=config.NUM_EPOCHS,\n",
        "        device=config.DEVICE,\n",
        "        save_path=config.MODEL_SAVE_PATH\n",
        "    )\n",
        "\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 6: LOAD BEST MODEL AND EVALUATE ON TEST SET\n",
        "    # ========================================================================\n",
        "    print_section(\"ðŸ“Š STEP 6: EVALUATING BEST MODEL ON TEST SET\")\n",
        "\n",
        "    # Load best model\n",
        "    print(f\"\\nLoading best model from {config.MODEL_SAVE_PATH}...\")\n",
        "    checkpoint = torch.load(config.MODEL_SAVE_PATH)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    print(f\"âœ… Loaded best model:\")\n",
        "    print(f\"   Epoch: {checkpoint['epoch']}\")\n",
        "    print(f\"   Validation AUC: {checkpoint['val_auc']:.4f}\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\nRunning evaluation on test set...\")\n",
        "    labels, preds, probs, cm = evaluate_model(model, test_loader, config.DEVICE)\n",
        "\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 7: VISUALIZE AND SAVE RESULTS\n",
        "    # ========================================================================\n",
        "    print_section(\"ðŸ“ˆ STEP 7: VISUALIZING RESULTS\")\n",
        "\n",
        "    print(\"\\nGenerating plots...\")\n",
        "\n",
        "    # Define plot paths\n",
        "    if config.SAVE_PLOTS:\n",
        "        history_path = os.path.join(config.PLOT_DIR, 'training_history.png')\n",
        "        cm_path = os.path.join(config.PLOT_DIR, 'confusion_matrix.png')\n",
        "        roc_path = os.path.join(config.PLOT_DIR, 'roc_curve.png')\n",
        "    else:\n",
        "        history_path = 'training_history.png'\n",
        "        cm_path = 'confusion_matrix.png'\n",
        "        roc_path = 'roc_curve.png'\n",
        "\n",
        "    # Plot training history\n",
        "    print(\"   ðŸ“Š Plotting training history...\")\n",
        "    plot_training_history(history, save_path=history_path)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    print(\"   ðŸ”¢ Plotting confusion matrix...\")\n",
        "    plot_confusion_matrix(cm, save_path=cm_path)\n",
        "\n",
        "    # Plot ROC curve\n",
        "    print(\"   ðŸ“‰ Plotting ROC curve...\")\n",
        "    plot_roc_curve(labels, probs, save_path=roc_path)\n",
        "\n",
        "\n",
        "    # ========================================================================\n",
        "    # FINAL SUMMARY\n",
        "    # ========================================================================\n",
        "    print_section(\"âœ… PIPELINE COMPLETE!\")\n",
        "\n",
        "    print(\"\\nðŸ“ Output Files:\")\n",
        "    print(f\"   Model: {config.MODEL_SAVE_PATH}\")\n",
        "    if config.SAVE_PLOTS:\n",
        "        print(f\"   Plots: {config.PLOT_DIR}/\")\n",
        "        print(f\"      - training_history.png\")\n",
        "        print(f\"      - confusion_matrix.png\")\n",
        "        print(f\"      - roc_curve.png\")\n",
        "    else:\n",
        "        print(f\"   Plots: Current directory\")\n",
        "        print(f\"      - training_history.png\")\n",
        "        print(f\"      - confusion_matrix.png\")\n",
        "        print(f\"      - roc_curve.png\")\n",
        "\n",
        "    print(\"\\nðŸ“Š Final Test Results:\")\n",
        "    test_acc = (preds == labels).mean()\n",
        "    test_auc = roc_auc_score(labels, probs)\n",
        "    print(f\"   Test Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"   Test AUC-ROC: {test_auc:.4f}\")\n",
        "\n",
        "    print(\"\\nðŸŽ‰ Training and evaluation completed successfully!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    return model, history, (labels, preds, probs)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# SCRIPT EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        # Run main pipeline\n",
        "        model, history, test_results = main()\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"ðŸŽŠ ALL DONE! You can now use the model for inference.\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"\\nNext steps:\")\n",
        "        print(\"1. Check the plots in the output directory\")\n",
        "        print(\"2. Use Step11_inference.py to make predictions on new images\")\n",
        "        print(\"3. Fine-tune hyperparameters if needed and retrain\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nâš ï¸  Training interrupted by user\")\n",
        "        print(\"Partial progress may have been saved\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\n\\nâŒ ERROR occurred during execution:\")\n",
        "        print(f\"   {type(e).__name__}: {str(e)}\")\n",
        "        print(\"\\nPlease check:\")\n",
        "        print(\"1. All file paths are correct\")\n",
        "        print(\"2. CSV files have the correct column names\")\n",
        "        print(\"3. Images exist and are readable\")\n",
        "        print(\"4. All previous step files (Step1-9) are present\")\n",
        "        raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0717c40009c94f7aaf7154aadacc8c2f",
            "89c9bbee34aa49808eb07d1f995a6cc4",
            "b27dc5554f1c403fb1c0d160e7631d96",
            "77e25d7d6ae2445794da038c3ecfc0ca",
            "3da1f5a810aa41298c6c0e3c1147d71f",
            "8ad997f2029448bf90c9620eb5816e5b",
            "befe3456b8874ab08c4b912cc86fbee3",
            "9d85f8e8f2fa48ba9950f12ca897cb61",
            "c3df8d1162f0425283dc35df35c1f37e",
            "a66606dad3ea4782b068c8ad7c4aaa6d",
            "0377d1af78334268bc3ddeab1ad40eac"
          ]
        },
        "id": "jy-UTiLiO2qi",
        "outputId": "1a5c1f40-8738-4299-c411-6d7821fe3647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  ðŸ¥ BINARY SKIN LESION CLASSIFICATION PIPELINE\n",
            "  ðŸ“Š Benign vs Malignant Classification using EfficientNet-B0\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "  ðŸ” VERIFYING PATHS\n",
            "======================================================================\n",
            "âœ… Image Directory: /content/local_data/images\n",
            "âœ… Lesion CSV: /content/local_data/lesion_grouping.csv\n",
            "âœ… Disease CSV: /content/local_data/groundtruth.csv\n",
            "\n",
            "âœ… All paths verified!\n",
            "âœ… Output directory created: plots\n",
            "\n",
            "======================================================================\n",
            "  ðŸ’» DEVICE INFORMATION\n",
            "======================================================================\n",
            "Device: cuda\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "CUDA Version: 12.6\n",
            "\n",
            "======================================================================\n",
            "  ðŸŽ² SETTING RANDOM SEED\n",
            "======================================================================\n",
            "âœ… Random seed set to 42 for reproducibility\n",
            "\n",
            "======================================================================\n",
            "  ðŸ“‚ STEP 1: DATA PREPARATION\n",
            "======================================================================\n",
            "\n",
            "Initializing DataPreparation class...\n",
            "============================================================\n",
            "ðŸ“Š DATA PREPARATION\n",
            "============================================================\n",
            "Lesion CSV shape: (10015, 3)\n",
            "Disease CSV shape: (10015, 8)\n",
            "\n",
            "Creating stratified train/val/test splits...\n",
            "\n",
            "âœ… Binary labels created:\n",
            "   Total images: 10015\n",
            "   Benign (0): 8061\n",
            "   Malignant (1): 1954\n",
            "   Class ratio (Benign:Malignant): 8061:1954\n",
            "\n",
            "âœ… Dataset splits created:\n",
            "   Training: 7009 images\n",
            "      - Benign: 5641\n",
            "      - Malignant: 1368\n",
            "   Validation: 1503 images\n",
            "      - Benign: 1210\n",
            "      - Malignant: 293\n",
            "   Test: 1503 images\n",
            "      - Benign: 1210\n",
            "      - Malignant: 293\n",
            "\n",
            "======================================================================\n",
            "  ðŸ“Š DATASET STATISTICS\n",
            "======================================================================\n",
            "\n",
            "Total Images: 10015\n",
            "\n",
            "Split        Total    Benign   Malignant  Ratio (B:M)\n",
            "------------------------------------------------------------\n",
            "Training     7009     5641     1368       5641:1368\n",
            "Validation   1503     1210     293        1210:293\n",
            "Test         1503     1210     293        1210:293\n",
            "\n",
            "============================================================\n",
            "Class Imbalance Information:\n",
            "Training set imbalance ratio: 4.12:1 (Benign:Malignant)\n",
            "This means benign samples are 4.1x more common\n",
            "âœ… Weighted sampling will be used to handle this imbalance!\n",
            "\n",
            "======================================================================\n",
            "  ðŸ”„ STEP 2: CREATING DATALOADERS\n",
            "======================================================================\n",
            "\n",
            "Initializing datasets with augmentation pipelines...\n",
            "============================================================\n",
            "ðŸ”„ CREATING DATALOADERS\n",
            "============================================================\n",
            "âœ… Dataset initialized with 7009 images\n",
            "   Class distribution: {0.0: np.int64(5641), 1.0: np.int64(1368)}\n",
            "âœ… Dataset initialized with 1503 images\n",
            "   Class distribution: {0.0: np.int64(1210), 1.0: np.int64(293)}\n",
            "âœ… Dataset initialized with 1503 images\n",
            "   Class distribution: {0.0: np.int64(1210), 1.0: np.int64(293)}\n",
            "âœ… Weighted sampler created:\n",
            "   Class counts: Benign=5641, Malignant=1368\n",
            "   Class weights: Benign=0.0002, Malignant=0.0007\n",
            "   This will oversample malignant cases during training!\n",
            "\n",
            "âœ… DataLoaders created:\n",
            "   Training batches: 220\n",
            "   Validation batches: 47\n",
            "   Test batches: 47\n",
            "\n",
            "âœ… DataLoaders Summary:\n",
            "   Batch Size: 32\n",
            "   Training Batches: 220 (7009 images)\n",
            "   Validation Batches: 47 (1503 images)\n",
            "   Test Batches: 47 (1503 images)\n",
            "   Note: Training uses weighted sampling to oversample malignant cases\n",
            "\n",
            "======================================================================\n",
            "  ðŸ¤– STEP 3: CREATING MODEL\n",
            "======================================================================\n",
            "\n",
            "Initializing EfficientNet-B0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0717c40009c94f7aaf7154aadacc8c2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ðŸ¤– MODEL ARCHITECTURE\n",
            "============================================================\n",
            "Model: EfficientNet-B0\n",
            "Pretrained: True\n",
            "Number of parameters: 4,008,829\n",
            "Trainable parameters: 4,008,829\n",
            "Device: cuda\n",
            "\n",
            "âœ… Model Summary:\n",
            "   Architecture: EfficientNet-B0\n",
            "   Pretrained: True\n",
            "   Total Parameters: 4,008,829\n",
            "   Trainable Parameters: 4,008,829\n",
            "   Model Size: ~16.0 MB\n",
            "   Device: cuda\n",
            "\n",
            "======================================================================\n",
            "  âš™ï¸  STEP 4: SETTING UP TRAINING COMPONENTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "  âš™ï¸  TRAINING SETUP\n",
            "======================================================================\n",
            "\n",
            "ðŸ“‰ Loss Function: BCEWithLogitsLoss\n",
            "   - Positive Weight: 4.12\n",
            "   - This gives 4.1x more importance to malignant samples\n",
            "\n",
            "ðŸŽ¯ Optimizer: AdamW\n",
            "   - Learning Rate: 0.0001\n",
            "   - Weight Decay: 1e-05\n",
            "\n",
            "ðŸ“… Scheduler: ReduceLROnPlateau\n",
            "   - Mode: Maximize (monitoring validation AUC)\n",
            "   - Factor: 0.5 (halves learning rate)\n",
            "   - Patience: 3 epochs\n",
            "\n",
            "======================================================================\n",
            "  ðŸ‹ï¸  STEP 5: TRAINING MODEL\n",
            "======================================================================\n",
            "\n",
            "Starting training for 30 epochs...\n",
            "Model will be saved to: best_efficientnet_b0_binary.pth\n",
            "\n",
            "Training Configuration:\n",
            "   Epochs: 30\n",
            "   Batch Size: 32\n",
            "   Learning Rate: 0.0001\n",
            "   Weight Decay: 1e-05\n",
            "\n",
            "Metrics tracked: Loss, Accuracy, Precision, Recall, F1, AUC-ROC\n",
            "Best model selection: Based on highest validation AUC-ROC\n",
            "============================================================\n",
            "ðŸš€ STARTING TRAINING\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Epoch 1/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:07<00:00,  3.28it/s, loss=1.45]\n",
            "Epoch 1 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:11<00:00,  4.21it/s, loss=0.729]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 1 Results:\n",
            "   Train Loss: 0.9047 | Train Acc: 0.7186\n",
            "   Val Loss: 0.6338 | Val Acc: 0.7259\n",
            "   Val Precision: 0.4111 | Val Recall: 0.9386\n",
            "   Val F1: 0.5717 | Val AUC: 0.9041\n",
            "   âœ… Best model saved! (AUC: 0.9041)\n",
            "\n",
            "============================================================\n",
            "Epoch 2/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:05<00:00,  3.35it/s, loss=1.21]\n",
            "Epoch 2 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:08<00:00,  5.31it/s, loss=0.667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 2 Results:\n",
            "   Train Loss: 0.7087 | Train Acc: 0.7583\n",
            "   Val Loss: 0.6102 | Val Acc: 0.7505\n",
            "   Val Precision: 0.4351 | Val Recall: 0.9386\n",
            "   Val F1: 0.5946 | Val AUC: 0.9171\n",
            "   âœ… Best model saved! (AUC: 0.9171)\n",
            "\n",
            "============================================================\n",
            "Epoch 3/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:03<00:00,  3.45it/s, loss=1.75]\n",
            "Epoch 3 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:09<00:00,  4.94it/s, loss=0.561]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 3 Results:\n",
            "   Train Loss: 0.6822 | Train Acc: 0.7744\n",
            "   Val Loss: 0.5411 | Val Acc: 0.8230\n",
            "   Val Precision: 0.5268 | Val Recall: 0.9044\n",
            "   Val F1: 0.6658 | Val AUC: 0.9288\n",
            "   âœ… Best model saved! (AUC: 0.9288)\n",
            "\n",
            "============================================================\n",
            "Epoch 4/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:02<00:00,  3.49it/s, loss=1.1]\n",
            "Epoch 4 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.60it/s, loss=0.442]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 4 Results:\n",
            "   Train Loss: 0.6267 | Train Acc: 0.7938\n",
            "   Val Loss: 0.5520 | Val Acc: 0.8283\n",
            "   Val Precision: 0.5359 | Val Recall: 0.8908\n",
            "   Val F1: 0.6692 | Val AUC: 0.9282\n",
            "\n",
            "============================================================\n",
            "Epoch 5/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:01<00:00,  3.56it/s, loss=1.31]\n",
            "Epoch 5 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.59it/s, loss=0.655]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 5 Results:\n",
            "   Train Loss: 0.5810 | Train Acc: 0.8120\n",
            "   Val Loss: 0.6152 | Val Acc: 0.8743\n",
            "   Val Precision: 0.6529 | Val Recall: 0.7577\n",
            "   Val F1: 0.7014 | Val AUC: 0.9278\n",
            "\n",
            "============================================================\n",
            "Epoch 6/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:02<00:00,  3.51it/s, loss=1.15]\n",
            "Epoch 6 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.52it/s, loss=0.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 6 Results:\n",
            "   Train Loss: 0.5504 | Train Acc: 0.8292\n",
            "   Val Loss: 0.5249 | Val Acc: 0.8603\n",
            "   Val Precision: 0.6000 | Val Recall: 0.8498\n",
            "   Val F1: 0.7034 | Val AUC: 0.9366\n",
            "   âœ… Best model saved! (AUC: 0.9366)\n",
            "\n",
            "============================================================\n",
            "Epoch 7/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:02<00:00,  3.50it/s, loss=0.827]\n",
            "Epoch 7 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.50it/s, loss=0.754]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 7 Results:\n",
            "   Train Loss: 0.5040 | Train Acc: 0.8462\n",
            "   Val Loss: 0.6927 | Val Acc: 0.8836\n",
            "   Val Precision: 0.6967 | Val Recall: 0.7133\n",
            "   Val F1: 0.7049 | Val AUC: 0.9314\n",
            "\n",
            "============================================================\n",
            "Epoch 8/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:02<00:00,  3.52it/s, loss=0.938]\n",
            "Epoch 8 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.50it/s, loss=0.442]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 8 Results:\n",
            "   Train Loss: 0.4626 | Train Acc: 0.8595\n",
            "   Val Loss: 0.5478 | Val Acc: 0.8483\n",
            "   Val Precision: 0.5758 | Val Recall: 0.8430\n",
            "   Val F1: 0.6842 | Val AUC: 0.9360\n",
            "\n",
            "============================================================\n",
            "Epoch 9/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:02<00:00,  3.50it/s, loss=1.64]\n",
            "Epoch 9 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.55it/s, loss=0.467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 9 Results:\n",
            "   Train Loss: 0.4617 | Train Acc: 0.8649\n",
            "   Val Loss: 0.5994 | Val Acc: 0.8749\n",
            "   Val Precision: 0.6378 | Val Recall: 0.8294\n",
            "   Val F1: 0.7211 | Val AUC: 0.9403\n",
            "   âœ… Best model saved! (AUC: 0.9403)\n",
            "\n",
            "============================================================\n",
            "Epoch 10/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:02<00:00,  3.50it/s, loss=1.31]\n",
            "Epoch 10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.36it/s, loss=0.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 10 Results:\n",
            "   Train Loss: 0.4380 | Train Acc: 0.8655\n",
            "   Val Loss: 0.6817 | Val Acc: 0.8916\n",
            "   Val Precision: 0.7110 | Val Recall: 0.7474\n",
            "   Val F1: 0.7288 | Val AUC: 0.9386\n",
            "\n",
            "============================================================\n",
            "Epoch 11/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:09<00:00,  3.18it/s, loss=1.16]\n",
            "Epoch 11 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:09<00:00,  4.85it/s, loss=0.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 11 Results:\n",
            "   Train Loss: 0.3831 | Train Acc: 0.8853\n",
            "   Val Loss: 0.6811 | Val Acc: 0.8989\n",
            "   Val Precision: 0.7423 | Val Recall: 0.7372\n",
            "   Val F1: 0.7397 | Val AUC: 0.9447\n",
            "   âœ… Best model saved! (AUC: 0.9447)\n",
            "\n",
            "============================================================\n",
            "Epoch 12/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:08<00:00,  3.22it/s, loss=1.93]\n",
            "Epoch 12 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.38it/s, loss=0.665]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 12 Results:\n",
            "   Train Loss: 0.3748 | Train Acc: 0.8921\n",
            "   Val Loss: 0.7277 | Val Acc: 0.8882\n",
            "   Val Precision: 0.6972 | Val Recall: 0.7543\n",
            "   Val F1: 0.7246 | Val AUC: 0.9403\n",
            "\n",
            "============================================================\n",
            "Epoch 13/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:05<00:00,  3.36it/s, loss=1.61]\n",
            "Epoch 13 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.43it/s, loss=1.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 13 Results:\n",
            "   Train Loss: 0.3600 | Train Acc: 0.8974\n",
            "   Val Loss: 0.9249 | Val Acc: 0.8922\n",
            "   Val Precision: 0.7435 | Val Recall: 0.6826\n",
            "   Val F1: 0.7117 | Val AUC: 0.9398\n",
            "\n",
            "============================================================\n",
            "Epoch 14/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:05<00:00,  3.33it/s, loss=1.58]\n",
            "Epoch 14 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:09<00:00,  4.76it/s, loss=0.766]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 14 Results:\n",
            "   Train Loss: 0.3476 | Train Acc: 0.9026\n",
            "   Val Loss: 0.9066 | Val Acc: 0.8955\n",
            "   Val Precision: 0.7464 | Val Recall: 0.7031\n",
            "   Val F1: 0.7241 | Val AUC: 0.9345\n",
            "\n",
            "============================================================\n",
            "Epoch 15/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:06<00:00,  3.30it/s, loss=1.6]\n",
            "Epoch 15 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:09<00:00,  4.86it/s, loss=0.571]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 15 Results:\n",
            "   Train Loss: 0.3391 | Train Acc: 0.9030\n",
            "   Val Loss: 0.7429 | Val Acc: 0.8929\n",
            "   Val Precision: 0.7185 | Val Recall: 0.7406\n",
            "   Val F1: 0.7294 | Val AUC: 0.9401\n",
            "\n",
            "============================================================\n",
            "Epoch 16/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:05<00:00,  3.35it/s, loss=1.21]\n",
            "Epoch 16 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.37it/s, loss=0.952]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 16 Results:\n",
            "   Train Loss: 0.3107 | Train Acc: 0.9131\n",
            "   Val Loss: 0.8841 | Val Acc: 0.9022\n",
            "   Val Precision: 0.7704 | Val Recall: 0.7099\n",
            "   Val F1: 0.7389 | Val AUC: 0.9406\n",
            "\n",
            "============================================================\n",
            "Epoch 17/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:05<00:00,  3.38it/s, loss=1.33]\n",
            "Epoch 17 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.38it/s, loss=1.22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 17 Results:\n",
            "   Train Loss: 0.2843 | Train Acc: 0.9202\n",
            "   Val Loss: 1.0948 | Val Acc: 0.8962\n",
            "   Val Precision: 0.7915 | Val Recall: 0.6348\n",
            "   Val F1: 0.7045 | Val AUC: 0.9412\n",
            "\n",
            "============================================================\n",
            "Epoch 18/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:04<00:00,  3.39it/s, loss=1.46]\n",
            "Epoch 18 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.53it/s, loss=1.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 18 Results:\n",
            "   Train Loss: 0.2747 | Train Acc: 0.9231\n",
            "   Val Loss: 1.0542 | Val Acc: 0.8982\n",
            "   Val Precision: 0.7823 | Val Recall: 0.6621\n",
            "   Val F1: 0.7172 | Val AUC: 0.9437\n",
            "\n",
            "============================================================\n",
            "Epoch 19/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:06<00:00,  3.30it/s, loss=1.37]\n",
            "Epoch 19 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:08<00:00,  5.24it/s, loss=1.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 19 Results:\n",
            "   Train Loss: 0.2704 | Train Acc: 0.9241\n",
            "   Val Loss: 1.0175 | Val Acc: 0.8962\n",
            "   Val Precision: 0.7546 | Val Recall: 0.6928\n",
            "   Val F1: 0.7224 | Val AUC: 0.9418\n",
            "\n",
            "============================================================\n",
            "Epoch 20/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:06<00:00,  3.30it/s, loss=1.07]\n",
            "Epoch 20 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.45it/s, loss=1.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 20 Results:\n",
            "   Train Loss: 0.2535 | Train Acc: 0.9235\n",
            "   Val Loss: 1.1818 | Val Acc: 0.8909\n",
            "   Val Precision: 0.7570 | Val Recall: 0.6485\n",
            "   Val F1: 0.6985 | Val AUC: 0.9418\n",
            "\n",
            "============================================================\n",
            "Epoch 21/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:05<00:00,  3.38it/s, loss=1.69]\n",
            "Epoch 21 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.43it/s, loss=1.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 21 Results:\n",
            "   Train Loss: 0.2447 | Train Acc: 0.9332\n",
            "   Val Loss: 1.2819 | Val Acc: 0.9015\n",
            "   Val Precision: 0.8085 | Val Recall: 0.6485\n",
            "   Val F1: 0.7197 | Val AUC: 0.9389\n",
            "\n",
            "============================================================\n",
            "Epoch 22/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:05<00:00,  3.33it/s, loss=0.951]\n",
            "Epoch 22 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.38it/s, loss=1.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 22 Results:\n",
            "   Train Loss: 0.2378 | Train Acc: 0.9301\n",
            "   Val Loss: 1.2591 | Val Acc: 0.8969\n",
            "   Val Precision: 0.7805 | Val Recall: 0.6553\n",
            "   Val F1: 0.7124 | Val AUC: 0.9421\n",
            "\n",
            "============================================================\n",
            "Epoch 23/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:07<00:00,  3.26it/s, loss=1.4]\n",
            "Epoch 23 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:08<00:00,  5.23it/s, loss=0.995]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 23 Results:\n",
            "   Train Loss: 0.2323 | Train Acc: 0.9341\n",
            "   Val Loss: 1.1117 | Val Acc: 0.9022\n",
            "   Val Precision: 0.7765 | Val Recall: 0.6997\n",
            "   Val F1: 0.7361 | Val AUC: 0.9409\n",
            "\n",
            "============================================================\n",
            "Epoch 24/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:06<00:00,  3.32it/s, loss=0.634]\n",
            "Epoch 24 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.35it/s, loss=1.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 24 Results:\n",
            "   Train Loss: 0.2204 | Train Acc: 0.9362\n",
            "   Val Loss: 1.0779 | Val Acc: 0.8989\n",
            "   Val Precision: 0.7787 | Val Recall: 0.6724\n",
            "   Val F1: 0.7216 | Val AUC: 0.9435\n",
            "\n",
            "============================================================\n",
            "Epoch 25/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:05<00:00,  3.37it/s, loss=0.601]\n",
            "Epoch 25 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.36it/s, loss=1.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 25 Results:\n",
            "   Train Loss: 0.2280 | Train Acc: 0.9352\n",
            "   Val Loss: 1.1183 | Val Acc: 0.8995\n",
            "   Val Precision: 0.7817 | Val Recall: 0.6724\n",
            "   Val F1: 0.7229 | Val AUC: 0.9434\n",
            "\n",
            "============================================================\n",
            "Epoch 26/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:04<00:00,  3.40it/s, loss=0.874]\n",
            "Epoch 26 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.43it/s, loss=0.747]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 26 Results:\n",
            "   Train Loss: 0.2291 | Train Acc: 0.9362\n",
            "   Val Loss: 1.0296 | Val Acc: 0.8975\n",
            "   Val Precision: 0.7439 | Val Recall: 0.7235\n",
            "   Val F1: 0.7336 | Val AUC: 0.9434\n",
            "\n",
            "============================================================\n",
            "Epoch 27/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:04<00:00,  3.42it/s, loss=0.667]\n",
            "Epoch 27 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.63it/s, loss=1.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 27 Results:\n",
            "   Train Loss: 0.2214 | Train Acc: 0.9357\n",
            "   Val Loss: 1.2808 | Val Acc: 0.8929\n",
            "   Val Precision: 0.7661 | Val Recall: 0.6485\n",
            "   Val F1: 0.7024 | Val AUC: 0.9413\n",
            "\n",
            "============================================================\n",
            "Epoch 28/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:05<00:00,  3.37it/s, loss=2.13]\n",
            "Epoch 28 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:09<00:00,  5.11it/s, loss=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 28 Results:\n",
            "   Train Loss: 0.2162 | Train Acc: 0.9372\n",
            "   Val Loss: 1.1449 | Val Acc: 0.8969\n",
            "   Val Precision: 0.7614 | Val Recall: 0.6860\n",
            "   Val F1: 0.7217 | Val AUC: 0.9408\n",
            "\n",
            "============================================================\n",
            "Epoch 29/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:05<00:00,  3.36it/s, loss=1.38]\n",
            "Epoch 29 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:09<00:00,  4.92it/s, loss=1.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 29 Results:\n",
            "   Train Loss: 0.2055 | Train Acc: 0.9426\n",
            "   Val Loss: 1.1557 | Val Acc: 0.8982\n",
            "   Val Precision: 0.7734 | Val Recall: 0.6758\n",
            "   Val F1: 0.7213 | Val AUC: 0.9425\n",
            "\n",
            "============================================================\n",
            "Epoch 30/30\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 220/220 [01:04<00:00,  3.40it/s, loss=0.594]\n",
            "Epoch 30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.41it/s, loss=1.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Epoch 30 Results:\n",
            "   Train Loss: 0.2131 | Train Acc: 0.9344\n",
            "   Val Loss: 1.4220 | Val Acc: 0.9002\n",
            "   Val Precision: 0.8017 | Val Recall: 0.6485\n",
            "   Val F1: 0.7170 | Val AUC: 0.9407\n",
            "\n",
            "============================================================\n",
            "âœ… TRAINING COMPLETE!\n",
            "   Best Validation AUC: 0.9447\n",
            "============================================================\n",
            "\n",
            "======================================================================\n",
            "  ðŸ“Š STEP 6: EVALUATING BEST MODEL ON TEST SET\n",
            "======================================================================\n",
            "\n",
            "Loading best model from best_efficientnet_b0_binary.pth...\n",
            "\n",
            "\n",
            "âŒ ERROR occurred during execution:\n",
            "   UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "\n",
            "Please check:\n",
            "1. All file paths are correct\n",
            "2. CSV files have the correct column names\n",
            "3. Images exist and are readable\n",
            "4. All previous step files (Step1-9) are present\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2171630579.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# Run main pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2171630579.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;31m# Load best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nLoading best model from {config.MODEL_SAVE_PATH}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_SAVE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1527\u001b[0m                         )\n\u001b[1;32m   1528\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m                 return _load(\n\u001b[1;32m   1531\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load the best model (with fix)\n",
        "checkpoint = torch.load('best_efficientnet_b0_binary.pth', weights_only=False)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "print(f\"âœ… Loaded best model from Epoch {checkpoint['epoch']}\")\n",
        "print(f\"   Best Validation AUC: {checkpoint['val_auc']:.4f}\")\n",
        "\n",
        "# Now evaluate on test set\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to('cuda')\n",
        "        labels = labels.float().unsqueeze(1)\n",
        "\n",
        "        logits = model(images)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs >= 0.5).float()\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate test metrics\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "all_preds = np.array(all_preds).flatten()\n",
        "all_probs = np.array(all_probs).flatten()\n",
        "all_labels = np.array(all_labels).flatten()\n",
        "\n",
        "test_acc = accuracy_score(all_labels, all_preds)\n",
        "test_precision = precision_score(all_labels, all_preds)\n",
        "test_recall = recall_score(all_labels, all_preds)\n",
        "test_f1 = f1_score(all_labels, all_preds)\n",
        "test_auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š TEST SET RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy:  {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "print(f\"Precision: {test_precision:.4f} ({test_precision*100:.2f}%)\")\n",
        "print(f\"Recall:    {test_recall:.4f} ({test_recall*100:.2f}%)\")\n",
        "print(f\"F1 Score:  {test_f1:.4f}\")\n",
        "print(f\"AUC-ROC:   {test_auc:.4f} ({test_auc*100:.2f}%) ðŸŒŸ\")\n",
        "\n",
        "print(\"\\nðŸ“‹ Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds,\n",
        "                           target_names=['Benign', 'Malignant'],\n",
        "                           digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQWKW9oUjSSN",
        "outputId": "7c773fea-09e7-450e-e66f-d9086d74a2cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded best model from Epoch 11\n",
            "   Best Validation AUC: 0.9447\n",
            "\n",
            "============================================================\n",
            "ðŸ“Š TEST SET RESULTS\n",
            "============================================================\n",
            "Accuracy:  0.9035 (90.35%)\n",
            "Precision: 0.7242 (72.42%)\n",
            "Recall:    0.8157 (81.57%)\n",
            "F1 Score:  0.7673\n",
            "AUC-ROC:   0.9518 (95.18%) ðŸŒŸ\n",
            "\n",
            "ðŸ“‹ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign     0.9540    0.9248    0.9392      1210\n",
            "   Malignant     0.7242    0.8157    0.7673       293\n",
            "\n",
            "    accuracy                         0.9035      1503\n",
            "   macro avg     0.8391    0.8702    0.8532      1503\n",
            "weighted avg     0.9092    0.9035    0.9056      1503\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "config = Config()\n",
        "train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset = create_dataloaders(\n",
        "        train_df=train_df,\n",
        "        val_df=val_df,\n",
        "        test_df=test_df,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        num_workers=config.NUM_WORKERS,\n",
        "        img_size=config.IMG_SIZE\n",
        "    )\n",
        "# ================= CONFIG =================\n",
        "MODEL_PATH = 'best_efficientnet_b0_binary.pth'\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assume model architecture is defined in create_model()\n",
        "model = create_model(pretrained=False, device=DEVICE)  # pretrained=False for loading checkpoint\n",
        "\n",
        "# ================= LOAD CHECKPOINT =================\n",
        "checkpoint = torch.load(MODEL_PATH, weights_only=False)  # Fix for PyTorch 2.6+\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "print(f\"âœ… Loaded checkpoint from {MODEL_PATH}\")\n",
        "print(f\"Epoch: {checkpoint.get('epoch', 'N/A')}, Val AUC: {checkpoint.get('val_auc', 'N/A')}\")\n",
        "\n",
        "# ================= EVALUATE =================\n",
        "# Make sure test_loader is defined\n",
        "labels, preds, probs, cm = evaluate_model(model, test_loader, DEVICE)\n",
        "\n",
        "# Compute metrics\n",
        "test_acc = (preds == labels).mean()\n",
        "test_auc = roc_auc_score(labels, probs)\n",
        "\n",
        "print(\"\\nðŸ“Š Test Results:\")\n",
        "print(f\"Accuracy: {test_acc:.4f}\")\n",
        "print(f\"AUC-ROC: {test_auc:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18w2pI_Jgf1a",
        "outputId": "8490e8b3-eb35-44c5-baea-937235a90595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ðŸ”„ CREATING DATALOADERS\n",
            "============================================================\n",
            "âœ… Dataset initialized with 7009 images\n",
            "   Class distribution: {0.0: np.int64(5641), 1.0: np.int64(1368)}\n",
            "âœ… Dataset initialized with 1503 images\n",
            "   Class distribution: {0.0: np.int64(1210), 1.0: np.int64(293)}\n",
            "âœ… Dataset initialized with 1503 images\n",
            "   Class distribution: {0.0: np.int64(1210), 1.0: np.int64(293)}\n",
            "âœ… Weighted sampler created:\n",
            "   Class counts: Benign=5641, Malignant=1368\n",
            "   Class weights: Benign=0.0002, Malignant=0.0007\n",
            "   This will oversample malignant cases during training!\n",
            "\n",
            "âœ… DataLoaders created:\n",
            "   Training batches: 220\n",
            "   Validation batches: 47\n",
            "   Test batches: 47\n",
            "============================================================\n",
            "ðŸ¤– MODEL ARCHITECTURE\n",
            "============================================================\n",
            "Model: EfficientNet-B0\n",
            "Pretrained: False\n",
            "Number of parameters: 4,008,829\n",
            "Trainable parameters: 4,008,829\n",
            "Device: cuda\n",
            "âœ… Loaded checkpoint from best_efficientnet_b0_binary.pth\n",
            "Epoch: 11, Val AUC: 0.9447183595182354\n",
            "============================================================\n",
            "ðŸ“Š EVALUATING MODEL ON TEST SET\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:10<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Test Results:\n",
            "   Accuracy: 0.9035\n",
            "   AUC-ROC: 0.9518\n",
            "\n",
            "ðŸ“‹ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign     0.9540    0.9248    0.9392      1210\n",
            "   Malignant     0.7242    0.8157    0.7673       293\n",
            "\n",
            "    accuracy                         0.9035      1503\n",
            "   macro avg     0.8391    0.8702    0.8532      1503\n",
            "weighted avg     0.9092    0.9035    0.9056      1503\n",
            "\n",
            "\n",
            "ðŸ”¢ Confusion Matrix:\n",
            "              Predicted\n",
            "              Benign  Malignant\n",
            "Actual Benign     1119     91\n",
            "       Malignant    54    239\n",
            "\n",
            "ðŸ“Š Test Results:\n",
            "Accuracy: 0.9035\n",
            "AUC-ROC: 0.9518\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1119   91]\n",
            " [  54  239]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete_Evaluation_From_Scratch.py\n",
        "\"\"\"\n",
        "Complete evaluation script that recreates everything needed\n",
        "Run this as a standalone script after training\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import *\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: IMPORT ALL NECESSARY COMPONENTS\n",
        "# ============================================================================\n",
        "\n",
        "# Import your custom modules (make sure they're available)\n",
        "from Step1_imports import set_seed\n",
        "from Step2_data_preparation import DataPreparation\n",
        "from Step3_augmentation import get_val_transforms\n",
        "from Step4_dataset import SkinLesionBinaryDataset\n",
        "from Step7_model import EfficientNetB0Binary\n",
        "from Step9_evaluation import plot_confusion_matrix, plot_roc_curve\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class EvalConfig:\n",
        "    # Paths (UPDATE THESE)\n",
        "    IMAGE_DIR = '/content/local_data/images'\n",
        "    LESION_CSV = '/content/local_data/lesion_grouping.csv'\n",
        "    DISEASE_CSV = '/content/local_data/groundtruth.csv'\n",
        "    MODEL_PATH = 'best_efficientnet_b0_binary.pth'\n",
        "\n",
        "    # Parameters\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_WORKERS = 2\n",
        "    IMG_SIZE = 224\n",
        "    TEST_SIZE = 0.15\n",
        "    VAL_SIZE = 0.15\n",
        "    SEED = 42\n",
        "\n",
        "    # Device\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    PLOT_DIR = 'plots'\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: RECREATE TEST DATASET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ðŸ“Š RECREATING TEST DATASET\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "set_seed(EvalConfig.SEED)\n",
        "\n",
        "# Prepare data\n",
        "data_prep = DataPreparation(\n",
        "    image_dir=EvalConfig.IMAGE_DIR,\n",
        "    lesion_csv_path=EvalConfig.LESION_CSV,\n",
        "    disease_csv_path=EvalConfig.DISEASE_CSV\n",
        ")\n",
        "\n",
        "train_df, val_df, test_df = data_prep.create_stratified_splits(\n",
        "    test_size=EvalConfig.TEST_SIZE,\n",
        "    val_size=EvalConfig.VAL_SIZE,\n",
        "    random_state=EvalConfig.SEED\n",
        ")\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = SkinLesionBinaryDataset(\n",
        "    test_df,\n",
        "    transform=get_val_transforms(img_size=EvalConfig.IMG_SIZE)\n",
        ")\n",
        "\n",
        "# Create test loader\n",
        "from torch.utils.data import DataLoader\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=EvalConfig.BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=EvalConfig.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Test dataset created: {len(test_dataset)} images\")\n",
        "print(f\"âœ… Test loader created: {len(test_loader)} batches\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: LOAD TRAINED MODEL\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ðŸ¤– LOADING TRAINED MODEL\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "model = EfficientNetB0Binary(pretrained=False, num_classes=1)\n",
        "model = model.to(EvalConfig.DEVICE)\n",
        "\n",
        "# Load checkpoint (WITH FIX FOR PYTORCH 2.6+)\n",
        "checkpoint = torch.load(EvalConfig.MODEL_PATH, weights_only=False)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "print(f\"\\nâœ… Model loaded from: {EvalConfig.MODEL_PATH}\")\n",
        "print(f\"   Training Epoch: {checkpoint['epoch']}\")\n",
        "print(f\"   Validation AUC: {checkpoint['val_auc']:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: EVALUATE ON TEST SET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ðŸ“Š EVALUATING ON TEST SET\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc='Testing'):\n",
        "        images = images.to(EvalConfig.DEVICE)\n",
        "        labels = labels.float().unsqueeze(1)\n",
        "\n",
        "        logits = model(images)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs >= 0.5).float()\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "all_preds = np.array(all_preds).flatten()\n",
        "all_probs = np.array(all_probs).flatten()\n",
        "all_labels = np.array(all_labels).flatten()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: CALCULATE AND DISPLAY METRICS\n",
        "# ============================================================================\n",
        "\n",
        "test_acc = accuracy_score(all_labels, all_preds)\n",
        "test_precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "test_recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "test_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "test_auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ðŸŽ¯ FINAL TEST SET RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n{'Metric':<15} {'Value':<10} {'Percentage'}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Accuracy':<15} {test_acc:<10.4f} {test_acc*100:.2f}%\")\n",
        "print(f\"{'Precision':<15} {test_precision:<10.4f} {test_precision*100:.2f}%\")\n",
        "print(f\"{'Recall':<15} {test_recall:<10.4f} {test_recall*100:.2f}%\")\n",
        "print(f\"{'F1 Score':<15} {test_f1:<10.4f} {test_f1*100:.2f}%\")\n",
        "print(f\"{'AUC-ROC':<15} {test_auc:<10.4f} {test_auc*100:.2f}% ðŸŒŸ\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ðŸ“‹ DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 70)\n",
        "print(classification_report(all_labels, all_preds,\n",
        "                           target_names=['Benign', 'Malignant'],\n",
        "                           digits=4))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(f\"\\nðŸ”¢ Confusion Matrix:\")\n",
        "print(f\"                    Predicted\")\n",
        "print(f\"              Benign      Malignant\")\n",
        "print(f\"Actual Benign    {cm[0][0]:5d}      {cm[0][1]:5d}\")\n",
        "print(f\"       Malignant {cm[1][0]:5d}      {cm[1][1]:5d}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: GENERATE PLOTS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ðŸ“ˆ GENERATING PLOTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "os.makedirs(EvalConfig.PLOT_DIR, exist_ok=True)\n",
        "\n",
        "# Confusion Matrix\n",
        "plot_confusion_matrix(cm, save_path=f'{EvalConfig.PLOT_DIR}/final_test_confusion_matrix.png')\n",
        "\n",
        "# ROC Curve\n",
        "plot_roc_curve(all_labels, all_probs, save_path=f'{EvalConfig.PLOT_DIR}/final_test_roc_curve.png')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"âœ… EVALUATION COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nðŸ“ Results saved in: {EvalConfig.PLOT_DIR}/\")\n",
        "print(f\"   - final_test_confusion_matrix.png\")\n",
        "print(f\"   - final_test_roc_curve.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "SuoI_YIAkW9f",
        "outputId": "99b07ba4-f86c-4468-8a49-2963df828a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'Step1_imports'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1998472605.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Import your custom modules (make sure they're available)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mStep1_imports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mStep2_data_preparation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataPreparation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mStep3_augmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_val_transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Step1_imports'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick evaluation (if test_loader exists)\n",
        "checkpoint = torch.load('best_efficientnet_b0_binary.pth', weights_only=False)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "labels, preds, probs, cm = evaluate_model(model, test_loader, device)\n",
        "plot_confusion_matrix(cm)\n",
        "plot_roc_curve(labels, probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "nhur96oQluX0",
        "outputId": "a1a33ce7-9f4a-4f61-a31b-3cc023cb6fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2820300371.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Quick evaluation (if test_loader exists)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_efficientnet_b0_binary.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "\n",
        "# Example: Save model to Drive\n",
        "shutil.copy('best_efficientnet_b0_binary.pth', '/content/drive/MyDrive/skin-disease-el/skin_lesion_model.pth')\n",
        "\n",
        "# Save plots to Drive\n",
        "shutil.copytree('plots', '/content/drive/MyDrive/skin_lesion_plots/confusion_matrix.png')\n",
        "shutil.copytree('plots', '/content/drive/MyDrive/skin_lesion_plots/roc_curve.png')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "8btqv5eGmdQk",
        "outputId": "b127f7a9-9873-460e-fefa-2c353f4d78ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "[Errno 17] File exists: '/content/drive/MyDrive/skin_lesion_plots/confusion_matrix.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3262721950.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Save plots to Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/skin_lesion_plots/confusion_matrix.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/skin_lesion_plots/roc_curve.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m     return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n\u001b[0m\u001b[1;32m    601\u001b[0m                      \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                      \u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36m_copytree\u001b[0;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mignored_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirs_exist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0muse_srcentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcopy2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcopy_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/skin_lesion_plots/confusion_matrix.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download model\n",
        "files.download('content/drive/MyDrive/skin-disease-el/skin_lesion_model.pth')\n",
        "\n",
        "# Download plots\n",
        "files.download('plots/final_test_confusion_matrix.png')\n",
        "files.download('plots/final_test_roc_curve.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "UuCzZbBcpdT7",
        "outputId": "0ca17698-c002-47da-93f1-2f72d699e342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: content/drive/MyDrive/skin-disease-el/skin_lesion_model.pth",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4186024600.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Download model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content/drive/MyDrive/skin-disease-el/skin_lesion_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Download plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: content/drive/MyDrive/skin-disease-el/skin_lesion_model.pth"
          ]
        }
      ]
    }
  ]
}